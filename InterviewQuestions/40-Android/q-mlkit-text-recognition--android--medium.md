---
id: android-398
title: "ML Kit Text Recognition / –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ML Kit"
aliases: ["ML Kit Text Recognition", "MLKit OCR", "OCR Android", "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ML Kit"]
topic: android
subtopics: [camera, media]
question_kind: android
difficulty: medium
original_language: en
language_tags: [en, ru]
status: draft
moc: moc-android
related: [q-android-async-primitives--android--easy, c-coroutines]
sources: []
created: 2025-10-15
updated: 2025-11-10
tags: [android/camera, android/media, difficulty/medium, image-processing, mlkit, ocr, text-recognition]

---

# –í–æ–ø—Ä–æ—Å (RU)

> –ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é ML Kit? –ö–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å on-device vs cloud —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ? –ö–∞–∫–æ–≤—ã best practices –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤ –∏ —Å–∫—Ä–∏–ø—Ç–æ–≤?

# Question (EN)

> How to implement text recognition using ML Kit? How to handle on-device vs cloud-based recognition? What are best practices for image preprocessing, optimization, and handling different languages and scripts?

---

## –û—Ç–≤–µ—Ç (RU)

ML Kit –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç on-device OCR –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤ —á–µ—Ä–µ–∑ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏: Latin, Chinese, Japanese, Korean, Devanagari (–∫–∞–∂–¥—ã–π —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ~10‚Äì30 MB –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏, –∫—Ä–æ–º–µ Latin, –∫–æ—Ç–æ—Ä—ã–π –≤—Å—Ç—Ä–æ–µ–Ω).

### –ë–∞–∑–æ–≤–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```kotlin
// app/build.gradle.kts
// –ü—Ä–∏–º–µ—Ä –¥–ª—è Latin –∏ Chinese Text Recognition v2
dependencies {
    implementation("com.google.mlkit:text-recognition-latin:16.0.0")
    implementation("com.google.mlkit:text-recognition-chinese:16.0.0")
}

// ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: Suspend-–æ–±–µ—Ä—Ç–∫–∞ + —è–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏
class TextRecognitionManager(context: Context) {
    private val latinRecognizer = TextRecognition.getClient(
        TextRecognizerOptions.DEFAULT_OPTIONS
    )

    suspend fun recognizeText(image: InputImage): Result<Text> =
        suspendCancellableCoroutine { continuation ->
            val task = latinRecognizer.process(image)
            task
                .addOnSuccessListener { result ->
                    if (continuation.isActive) {
                        continuation.resume(Result.success(result))
                    }
                }
                .addOnFailureListener { e ->
                    if (continuation.isActive) {
                        continuation.resume(Result.failure(e))
                    }
                }

            // –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ –∫–æ—Ä—É—Ç–∏–Ω—ã –º–æ–∂–Ω–æ –æ—Ç–º–µ–Ω–∏—Ç—å Task, –µ—Å–ª–∏ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ
            continuation.invokeOnCancellation {
                task.cancel()
            }
        }

    fun close() = latinRecognizer.close()
}

// üîé –ü–ª–æ—Ö–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ: —Å–æ–∑–¥–∞–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ recognizer-—ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –±–µ–∑ –∑–∞–∫—Ä—ã—Ç–∏—è
// –ø–æ–≤—ã—à–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏/—Ä–µ—Å—É—Ä—Å–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–∫–æ—É–ø –∏ close(), –∫–æ–≥–¥–∞ –±–æ–ª–µ–µ –Ω–µ –Ω—É–∂–Ω–æ.
class BadManager {
    private val recognizer = TextRecognition.getClient(/* options */)
}
```

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**
- Latin —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Å—Ç—Ä–æ–µ–Ω–æ (–º–æ–¥–µ–ª—å –ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π), –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏.
- On-device: –±—ã—Å—Ç—Ä–æ (~–¥–µ—Å—è—Ç–∫–∏-—Å–æ—Ç–Ω–∏ –º—Å), offline, –ø—Ä–∏–≤–∞—Ç–Ω–æ; –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.
- –û–±–ª–∞—á–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (Cloud Vision / Firebase ML) ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å; –≤—ã–±–∏—Ä–∞–π—Ç–µ –µ–≥–æ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∂—ë—Å—Ç–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö –∫ –∫–∞—á–µ—Å—Ç–≤—É, —Ä–µ–¥–∫–∏–º —Å–∫—Ä–∏–ø—Ç–∞–º –∏–ª–∏ —Å–ª–æ–∂–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.
- –ó–∞–∫—Ä—ã–≤–∞–π—Ç–µ recognizers, –∫–æ–≥–¥–∞ –æ–Ω–∏ –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ onCleared() `ViewModel` –∏–ª–∏ –ø—Ä–∏ —É–Ω–∏—á—Ç–æ–∂–µ–Ω–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞), —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã.

### Image Preprocessing

–ö–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏. –ü—Ä–∞–∫—Ç–∏—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã: –æ—Ç 640x480 –¥–æ 1920x1080; –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–∏–µ —Ä–∞–∑–º–µ—Ä—ã –¥–∞—é—Ç —É–±—ã–≤–∞—é—â—É—é –æ—Ç–¥–∞—á—É –∏ –ø–æ–≤—ã—à–∞—é—Ç –∑–∞–¥–µ—Ä–∂–∫–∏.

```kotlin
class ImagePreprocessor {
    suspend fun preprocessImage(bitmap: Bitmap): Bitmap =
        withContext(Dispatchers.Default) {
            var processed = bitmap

            // 1. ‚úÖ Resize, –µ—Å–ª–∏ –æ–¥–Ω–∞ –∏–∑ —Å—Ç–æ—Ä–æ–Ω > 1920
            if (bitmap.width > 1920 || bitmap.height > 1920) {
                val scale = min(1920f / bitmap.width, 1920f / bitmap.height)
                processed = Bitmap.createScaledBitmap(
                    bitmap,
                    (bitmap.width * scale).toInt(),
                    (bitmap.height * scale).toInt(),
                    true
                )
            }

            // 2. ‚úÖ Grayscale: —É–ø—Ä–æ—â–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –∏ –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö
            val result = Bitmap.createBitmap(processed.width, processed.height, Bitmap.Config.ARGB_8888)
            Canvas(result).drawBitmap(processed, 0f, 0f, Paint().apply {
                colorFilter = ColorMatrixColorFilter(ColorMatrix().apply { setSaturation(0f) })
            })

            result
        }
}
```

**–ó–∞–º–µ—á–∞–Ω–∏—è:**
- –ü–µ—Ä–µ–≤–æ–¥ –≤ grayscale –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —á–∞—Å—Ç–æ –ø–æ–º–æ–≥–∞—é—Ç –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –ø—Ä–∏—Ä–æ—Å—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏ –¥–∞–Ω–Ω—ã—Ö; –ª—é–±—ã–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã —É–ª—É—á—à–µ–Ω–∏—è —Å–ª–µ–¥—É–µ—Ç —Å—á–∏—Ç–∞—Ç—å –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–º–∏, –∞ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏.
- –ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –Ω–∏–∑–∫–æ–π –æ—Å–≤–µ—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Å–ª–∞–±–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.

### Real-time Camera Recognition

```kotlin
@HiltViewModel
class TextRecognitionViewModel @Inject constructor(
    private val manager: TextRecognitionManager
) : ViewModel() {
    private val _recognizedText = MutableStateFlow<String?>(null)
    val recognizedText: StateFlow<String?> = _recognizedText

    private var lastProcessed = 0L
    private val throttleMs = 1000L  // ‚úÖ 1 frame/sec (–ø—Ä–∏–º–µ—Ä —Ä–∞–∑—É–º–Ω–æ–≥–æ —Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥–∞)

    @OptIn(ExperimentalGetImage::class)
    fun analyzeImage(imageProxy: ImageProxy) {
        val now = System.currentTimeMillis()

        // ‚úÖ –¢—Ä–æ—Ç—Ç–ª–∏–Ω–≥ —É–º–µ–Ω—å—à–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ CPU –∏ —ç–∫–æ–Ω–æ–º–∏—Ç –±–∞—Ç–∞—Ä–µ—é
        if (now - lastProcessed < throttleMs) {
            imageProxy.close()
            return
        }

        lastProcessed = now
        val mediaImage = imageProxy.image
        if (mediaImage == null) {
            imageProxy.close()
            return
        }

        val inputImage = InputImage.fromMediaImage(
            mediaImage,
            imageProxy.imageInfo.rotationDegrees
        )

        viewModelScope.launch {
            try {
                manager.recognizeText(inputImage)
                    .onSuccess { _recognizedText.value = it.text }
                    .onFailure { /* –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ / –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ */ }
            } finally {
                imageProxy.close()  // ‚úÖ –í—Å–µ–≥–¥–∞ –∑–∞–∫—Ä—ã–≤–∞–µ–º
            }
        }
    }

    override fun onCleared() {
        manager.close()
        super.onCleared()
    }
}

// ‚ùå –ü–ª–æ—Ö–æ: –ø–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä (30 FPS) —Ç—è–∂—ë–ª—ã–º–∏ ML-–≤—ã–∑–æ–≤–∞–º–∏
fun bad(imageProxy: ImageProxy) {
    // –≠—Ç–æ –ø—Ä–∏–≤–µ–¥—ë—Ç –∫ –≤—ã—Å–æ–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–µ CPU/–±–∞—Ç–∞—Ä–µ–∏ –∏ –æ—á–µ—Ä–µ–¥–∏ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤.
    // viewModelScope.launch { manager.recognizeText(...) }
}
```

### Document Scanning + Data Extraction

```kotlin
class DocumentScannerViewModel @Inject constructor(
    private val manager: TextRecognitionManager,
    private val preprocessor: ImagePreprocessor
) : ViewModel() {

    suspend fun scanDocument(uri: Uri, context: Context): Result<ScannedDocument> {
        return try {
            val bitmap = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.P) {
                ImageDecoder.decodeBitmap(ImageDecoder.createSource(context.contentResolver, uri))
            } else {
                @Suppress("DEPRECATION")
                MediaStore.Images.Media.getBitmap(context.contentResolver, uri)
            }

            val processed = preprocessor.preprocessImage(bitmap)
            val inputImage = InputImage.fromBitmap(processed, 0)

            manager.recognizeText(inputImage).map { text ->
                ScannedDocument(
                    fullText = text.text,
                    // –£ API TextRecognition –Ω–µ—Ç –æ–±—â–µ–≥–æ –ø–æ–ª—è confidence –¥–ª—è –≤—Å–µ–≥–æ –±–ª–æ–∫–∞ —Ç–µ–∫—Å—Ç–∞;
                    // –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞–ª–∏—á–Ω—ã–µ confidence-–ø–æ–ª—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤/—Å–∏–º–≤–æ–ª–æ–≤.
                    confidenceHint = null,
                    emails = extractEmails(text.text),
                    phoneNumbers = extractPhones(text.text)
                )
            }
        } catch (e: Exception) {
            Result.failure(e)
        }
    }

    // ‚úÖ Regex extraction (–ø—Ä–∏–º–µ—Ä, –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å false positives)
    private fun extractEmails(text: String) =
        Regex("[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}")
            .findAll(text).map { it.value }.toList()

    private fun extractPhones(text: String) =
        Regex("\\+?\\d{1,4}[-.\\s]?\\(?\\d{1,3}?\\)?[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}")
            .findAll(text).map { it.value }.toList()
}

data class ScannedDocument(
    val fullText: String,
    val confidenceHint: Float?,  // –ú–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º –∏–ª–∏ null, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ API
    val emails: List<String>,
    val phoneNumbers: List<String>
)
```

### Model Management

```kotlin
enum class ScriptType { LATIN, CHINESE, JAPANESE, KOREAN, DEVANAGARI }

class ModelDownloadManager(private val context: Context) {
    // ‚úÖ –ü—Ä–∏–º–µ—Ä: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—Ü–∏–π)
    fun downloadModelIfNeeded(script: ScriptType, onProgress: (Int) -> Unit) {
        if (script == ScriptType.LATIN) return  // Latin –º–æ–¥–µ–ª—å —É–∂–µ –¥–æ—Å—Ç—É–ø–Ω–∞ —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π

        val conditions = DownloadConditions.Builder()
            .requireWifi()
            .build()

        val options = when (script) {
            ScriptType.CHINESE -> ChineseTextRecognizerOptions.Builder().build()
            ScriptType.JAPANESE -> JapaneseTextRecognizerOptions.Builder().build()
            ScriptType.KOREAN -> KoreanTextRecognizerOptions.Builder().build()
            ScriptType.DEVANAGARI -> DevanagariTextRecognizerOptions.Builder().build()
            ScriptType.LATIN -> return
        }

        val client = TextRecognition.getClient(options)
        client.downloadModelIfNeeded(conditions)
            .addOnProgressListener { snapshot ->
                val total = snapshot.totalByteCount
                if (total > 0) {
                    val progress = (snapshot.bytesDownloaded * 100 / total).toInt()
                    onProgress(progress)
                }
            }
    }
}
```

### Best Practices

**–ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã):**
- –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: –Ω–µ –Ω–∏–∂–µ 640x480; –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ 1920x1080 –æ–±—ã—á–Ω–æ –¥–∞—ë—Ç —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é.
- –û—Å–≤–µ—â–µ–Ω–∏–µ: —Ö–æ—Ä–æ—à–µ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å; –∏–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã—Ö –±–ª–∏–∫–æ–≤ –∏ —à—É–º–∞.
- ML Kit –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–∏–ø–∏—á–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã (rotationDegrees), —É–º–µ—Ä–µ–Ω–Ω—ã–π –Ω–∞–∫–ª–æ–Ω –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è, –Ω–æ —Å–∏–ª—å–Ω—ã–π skew –ª—É—á—à–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –∫–ª–∏–µ–Ω—Ç–∞.

**Preprocessing (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ):**
1. –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ (—É–º–µ–Ω—å—à–µ–Ω–∏–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π).
2. –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç; –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî –∞–≤—Ç–æ–∫–æ–Ω—Ç—Ä–∞—Å—Ç –∏–ª–∏ –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è.
3. Grayscale –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± —É–º–µ–Ω—å—à–∏—Ç—å —à—É–º —Ü–≤–µ—Ç–æ–≤–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –µ—Å–ª–∏ —ç—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

**Performance:**
- –¢—Ä–æ—Ç—Ç–ª–∏–Ω–≥: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä, –∞ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 500‚Äì1000 –º—Å) –∏–ª–∏ –ø–æ —Å–æ–±—ã—Ç–∏—é.
- Heavy-–ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–∞ Dispatchers.Default / worker threads.
- –ó–∞–∫—Ä—ã–≤–∞—Ç—å recognizer'—ã, –∫–æ–≥–¥–∞ –æ–Ω–∏ –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è.
- –ò–∑–±–µ–≥–∞—Ç—å –æ—á–µ—Ä–µ–¥–∏ –∏–∑ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö ImageProxy: –≤—Å–µ–≥–¥–∞ –∑–∞–∫—Ä—ã–≤–∞–π—Ç–µ –∫–∞–¥—Ä.

**Accuracy:**
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –∏ –ø–æ—Ä–æ–≥–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏; –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ä–æ–¥–µ 0.8 ‚Äî —ç—Ç–æ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è, –∞ –Ω–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ.
- –ú–æ–¥–µ–ª–∏ –¥–ª—è –ª–∞—Ç–∏–Ω–∏—Ü—ã –æ–±—ã—á–Ω–æ –±—ã—Å—Ç—Ä–µ–µ –∏ –º–æ–≥—É—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Å–ª–æ–∂–Ω—ã–º–∏ –∏–µ—Ä–æ–≥–ª–∏—Ñ–∏—á–µ—Å–∫–∏–º–∏ —Å–∫—Ä–∏–ø—Ç–∞–º–∏.
- –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ (regex, –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤) –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ç—Å–µ—á—å –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è, –Ω–æ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç 100% —Ç–æ—á–Ω–æ—Å—Ç—å.

---

## Answer (EN)

ML Kit provides on-device OCR for different scripts via separate modules: Latin, Chinese, Japanese, Korean, Devanagari. Latin is bundled via its library; other script models are downloaded on demand (typically ~10‚Äì30 MB each).

### Basic Implementation

```kotlin
// app/build.gradle.kts
// Example for Text Recognition v2 (Latin + Chinese)
dependencies {
    implementation("com.google.mlkit:text-recognition-latin:16.0.0")
    implementation("com.google.mlkit:text-recognition-chinese:16.0.0")
}

// ‚úÖ Correct: suspend wrapper + explicit resource management
class TextRecognitionManager(context: Context) {
    private val latinRecognizer = TextRecognition.getClient(
        TextRecognizerOptions.DEFAULT_OPTIONS
    )

    suspend fun recognizeText(image: InputImage): Result<Text> =
        suspendCancellableCoroutine { continuation ->
            val task = latinRecognizer.process(image)
            task
                .addOnSuccessListener { result ->
                    if (continuation.isActive) {
                        continuation.resume(Result.success(result))
                    }
                }
                .addOnFailureListener { e ->
                    if (continuation.isActive) {
                        continuation.resume(Result.failure(e))
                    }
                }

            // Optionally cancel the Task if coroutine is cancelled
            continuation.invokeOnCancellation {
                task.cancel()
            }
        }

    fun close() = latinRecognizer.close()
}

// üîé Not ideal: creating many recognizer instances and never closing them
// can waste memory/resources. Prefer scoped usage and close() when done.
class BadManager {
    private val recognizer = TextRecognition.getClient(/* options */)
}
```

**Key points:**
- Latin model is available with the library; other script models are downloaded on first use.
- On-device: fast (tens to low hundreds of ms), offline, privacy-preserving; suitable for most use cases.
- Cloud-based text recognition (Cloud Vision / Firebase ML) is a separate product; use it only when you need higher accuracy on complex layouts, rare scripts, or server-side processing.
- Close recognizers when they are no longer needed (e.g., in `ViewModel`.onCleared or component teardown) to release resources.

### Image Preprocessing

Image quality is critical for accuracy. Practical dimensions: from 640x480 up to around 1920x1080; much higher resolutions increase latency with diminishing returns.

```kotlin
class ImagePreprocessor {
    suspend fun preprocessImage(bitmap: Bitmap): Bitmap =
        withContext(Dispatchers.Default) {
            var processed = bitmap

            // 1. ‚úÖ Resize if one side > 1920
            if (bitmap.width > 1920 || bitmap.height > 1920) {
                val scale = min(1920f / bitmap.width, 1920f / bitmap.height)
                processed = Bitmap.createScaledBitmap(
                    bitmap,
                    (bitmap.width * scale).toInt(),
                    (bitmap.height * scale).toInt(),
                    true
                )
            }

            // 2. ‚úÖ Grayscale: simplifies the image and can help robustness in some cases
            val result = Bitmap.createBitmap(processed.width, processed.height, Bitmap.Config.ARGB_8888)
            Canvas(result).drawBitmap(processed, 0f, 0f, Paint().apply {
                colorFilter = ColorMatrixColorFilter(ColorMatrix().apply { setSaturation(0f) })
            })

            result
        }
}
```

**Notes:**
- Grayscale and resizing often help balance speed and quality, but exact gains depend on device and data; any specific improvement figures should be treated as rough heuristics rather than guarantees.
- Contrast enhancement is useful for low-light or low-contrast input but is not universally required.

### Real-time Camera Recognition

```kotlin
@HiltViewModel
class TextRecognitionViewModel @Inject constructor(
    private val manager: TextRecognitionManager
) : ViewModel() {
    private val _recognizedText = MutableStateFlow<String?>(null)
    val recognizedText: StateFlow<String?> = _recognizedText

    private var lastProcessed = 0L
    private val throttleMs = 1000L  // ‚úÖ 1 frame/sec as a reasonable throttling example

    @OptIn(ExperimentalGetImage::class)
    fun analyzeImage(imageProxy: ImageProxy) {
        val now = System.currentTimeMillis()

        // ‚úÖ Throttling prevents CPU overload and reduces battery drain
        if (now - lastProcessed < throttleMs) {
            imageProxy.close()
            return
        }

        lastProcessed = now
        val mediaImage = imageProxy.image
        if (mediaImage == null) {
            imageProxy.close()
            return
        }

        val inputImage = InputImage.fromMediaImage(
            mediaImage,
            imageProxy.imageInfo.rotationDegrees
        )

        viewModelScope.launch {
            try {
                manager.recognizeText(inputImage)
                    .onSuccess { _recognizedText.value = it.text }
                    .onFailure { /* log / handle error */ }
            } finally {
                imageProxy.close()  // ‚úÖ Always close
            }
        }
    }

    override fun onCleared() {
        manager.close()
        super.onCleared()
    }
}

// ‚ùå Not recommended: running heavy recognition on every frame (~30 FPS)
fun bad(imageProxy: ImageProxy) {
    // This will saturate CPU and drain battery; avoid naive per-frame processing.
    // viewModelScope.launch { manager.recognizeText(...) }
}
```

### Document Scanning + Data Extraction

```kotlin
class DocumentScannerViewModel @Inject constructor(
    private val manager: TextRecognitionManager,
    private val preprocessor: ImagePreprocessor
) : ViewModel() {

    suspend fun scanDocument(uri: Uri, context: Context): Result<ScannedDocument> {
        return try {
            val bitmap = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.P) {
                ImageDecoder.decodeBitmap(ImageDecoder.createSource(context.contentResolver, uri))
            } else {
                @Suppress("DEPRECATION")
                MediaStore.Images.Media.getBitmap(context.contentResolver, uri)
            }

            val processed = preprocessor.preprocessImage(bitmap)
            val inputImage = InputImage.fromBitmap(processed, 0)

            manager.recognizeText(inputImage).map { text ->
                ScannedDocument(
                    fullText = text.text,
                    // Text Recognition API does not expose a single global confidence.
                    // If needed, derive your own metric from element/line/character confidences.
                    confidenceHint = null,
                    emails = extractEmails(text.text),
                    phoneNumbers = extractPhones(text.text)
                )
            }
        } catch (e: Exception) {
            Result.failure(e)
        }
    }

    // ‚úÖ Regex extraction example (may produce false positives)
    private fun extractEmails(text: String) =
        Regex("[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}")
            .findAll(text).map { it.value }.toList()

    private fun extractPhones(text: String) =
        Regex("\\+?\\d{1,4}[-.\\s]?\\(?\\d{1,3}?\\)?[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}")
            .findAll(text).map { it.value }.toList()
}

data class ScannedDocument(
    val fullText: String,
    val confidenceHint: Float?,  // null or custom aggregate metric
    val emails: List<String>,
    val phoneNumbers: List<String>
)
```

### Model Management

```kotlin
enum class ScriptType { LATIN, CHINESE, JAPANESE, KOREAN, DEVANAGARI }

class ModelDownloadManager(private val context: Context) {
    // ‚úÖ Example: proactively ensure model download for a given script using v2 APIs
    fun downloadModelIfNeeded(script: ScriptType, onProgress: (Int) -> Unit) {
        if (script == ScriptType.LATIN) return  // Latin is available with the library

        val conditions = DownloadConditions.Builder()
            .requireWifi()
            .build()

        val options = when (script) {
            ScriptType.CHINESE -> ChineseTextRecognizerOptions.Builder().build()
            ScriptType.JAPANESE -> JapaneseTextRecognizerOptions.Builder().build()
            ScriptType.KOREAN -> KoreanTextRecognizerOptions.Builder().build()
            ScriptType.DEVANAGARI -> DevanagariTextRecognizerOptions.Builder().build()
            ScriptType.LATIN -> return
        }

        val client = TextRecognition.getClient(options)
        client.downloadModelIfNeeded(conditions)
            .addOnProgressListener { snapshot ->
                val total = snapshot.totalByteCount
                if (total > 0) {
                    val progress = (snapshot.bytesDownloaded * 100 / total).toInt()
                    onProgress(progress)
                }
            }
    }
}
```

### Best Practices

**Image Quality (critical factors):**
- Resolution: at least 640x480; up to around 1920x1080 is typically a good balance.
- Lighting: good, even lighting significantly improves accuracy; avoid glare and heavy noise.
- ML Kit handles normal rotations (via rotationDegrees) and moderate skew; strong skew/perspective may require client-side correction.

**Preprocessing (in order of importance):**
1. Reasonable downscaling of very large images.
2. Adequate lighting and contrast; apply contrast/thresholding when needed.
3. Grayscale as a simple, sometimes helpful optimization.

**Performance:**
- Throttle processing (e.g., every 500‚Äì1000 ms) or trigger on demand instead of every frame.
- Run heavy preprocessing on Dispatchers.Default / background threads.
- Always close ImageProxy and release recognizers when no longer needed.
- Avoid building up a backlog of frames.

**Accuracy:**
- Tune confidence thresholds empirically for your use case; 0.8 is a common starting point, not a rule.
- Latin models are typically faster; complex scripts (CJK, etc.) may be slower and need more tuning.
- Post-processing (regex, checksums, format validation) helps filter out false positives.

---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã (RU)

1. –ö–∞–∫ ML Kit –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–≤—ë—Ä–Ω—É—Ç—ã–π –∏–ª–∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–∫–∞–∂—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏?
2. –ö–∞–∫–æ–≤—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ trade-off'—ã –º–µ–∂–¥—É on-device –∏ –æ–±–ª–∞—á–Ω—ã–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Ç–µ–∫—Å—Ç–∞ –≤ –ø—Ä–æ–¥–µ?
3. –ö–∞–∫ —Å–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω CameraX + ML Kit, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—á–µ—Ä–µ–¥–∏ –∫–∞–¥—Ä–æ–≤ –∏ ANR?
4. –ö–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —è–∑—ã–∫–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π + –∫–∏—Ç–∞–π—Å–∫–∏–π) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö recognizer'–æ–≤?
5. –ö–∞–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –∏ –≤ –±—ç–∫–µ–Ω–¥–µ?

## Follow-ups

1. How does ML Kit handle rotated or skewed text in images?
2. What are the trade-offs between on-device and cloud-based text recognition for production apps?
3. How to design a CameraX + ML Kit pipeline to avoid frame backlog and ANRs?
4. How to support mixed-language documents (e.g., English + Chinese) with multiple recognizers?
5. How to persist and sync recognized text securely on-device and in the backend?

## –°—Å—ã–ª–∫–∏ (RU)

- [[c-coroutines]]
- [ML Kit Text Recognition Guide](https://developers.google.com/ml-kit/vision/text-recognition)
- [CameraX Image Analysis](https://developer.android.com/training/camerax/analyze)

## References

- [[c-coroutines]]
- [ML Kit Text Recognition Guide](https://developers.google.com/ml-kit/vision/text-recognition)
- [CameraX Image Analysis](https://developer.android.com/training/camerax/analyze)

## –°–≤—è–∑–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã (RU)

### –ë–∞–∑–∞ (–ø—Ä–æ—â–µ)
- [[q-android-async-primitives--android--easy]]

### –ü–æ—Ö–æ–∂–∏–µ (—Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å)
- [[q-mlkit-object-detection--android--medium]]
- [[q-biometric-authentication--android--medium]]
- [[q-android-performance-measurement-tools--android--medium]]

### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ (—Å–ª–æ–∂–Ω–µ–µ)
- [[q-mlkit-custom-models--android--hard]]
- [[q-tflite-acceleration-strategies--android--hard]]

## Related Questions

### Prerequisites (Easier)
- [[q-android-async-primitives--android--easy]]

### Related (Same Level)
- [[q-mlkit-object-detection--android--medium]]
- [[q-biometric-authentication--android--medium]]
- [[q-android-performance-measurement-tools--android--medium]]

### Advanced (Harder)
- [[q-mlkit-custom-models--android--hard]]
- [[q-tflite-acceleration-strategies--android--hard]]
